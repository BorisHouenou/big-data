```{r db-modeling, include = FALSE}
eval_model <- FALSE
if(Sys.getenv("GLOBAL_EVAL") != "") eval_model <- Sys.getenv("GLOBAL_EVAL")
```

```{r, eval = eval_model, include = FALSE}
library(tidymodels)
library(modeldb)
library(dbplot)
library(pins)
library(dbplyr)
library(RPostgres)
library(connections)
library(config)
```

# Modeling with databases

## Single step sampling
*Use PostgreSQL TABLESAMPLE clause*

1. Use `connection_open()` to open a Database connection
    ```{r, eval = eval_model}
    con <- connection_open(
      RPostgres::Postgres(),
      host =  "localhost",
      user = get("user", config = "datawarehouse"),
      password = get("password", config = "datawarehouse"),
      port = 5432,
      dbname = "postgres",
      bigint = "integer"
    )
    ```

1. Set the `orders` variable to point to the **orders** table
    ```{r, eval = eval_model}
    orders <- tbl(con, in_schema("datawarehouse", "orders"))
    ```

1. Set the `orders_view` variable to point to the **v_orders** table
    ```{r, eval = eval_model}
    orders_view <- tbl(con, in_schema("datawarehouse", "v_orders"))
    ```

1. Pipe `orders` into the function `show_query()`
    ```{r, eval = eval_model}
    orders %>%
      show_query()
    ```

1. Pipe the previous command into the `class()` function to see the kind of output `show_query()` returns
    ```{r, eval = eval_model}
    orders %>%
      show_query() %>%
      class()
    ```

1. Replace `show_query()` with `remote_query()` to compare the output types
    ```{r, eval = eval_model}
    orders %>%
      remote_query() %>%
      class()
    ```

1. Replace `class()` with `build_sql()`.  Use `con` as the value for the `con` argument
    ```{r, eval = eval_model}
    orders %>%
      remote_query() %>%
      build_sql(con = con)
    ```

1. Add *" TABLESAMPLE BERNOULLI (0.1)"* to `build_sql()` as another `...` argument
    ```{r, eval = eval_model}
    orders %>%
      remote_query() %>%
      build_sql(con = con, " TABLESAMPLE BERNOULLI (0.1)")
    ```

1. Pipe the code into `tbl()`.  Use `con` for the `con` argument, and `.` for the rest
    ```{r, eval = eval_model}
    orders %>%
      remote_query() %>%
      build_sql(con = con, " TABLESAMPLE BERNOULLI (0.1)") %>%
      tbl(con, .) 
    ```

1. Use `inner_join()` to add the information from the `orders_view` pointer, use `order_id` as the matching field
    ```{r, eval = eval_model}
    orders %>%
      remote_query() %>%
      build_sql(con = con, " TABLESAMPLE BERNOULLI (0.1)") %>%
      tbl(con, .)  %>%
      inner_join(orders_view, by = "order_id") 
    ```

1. Assign the resulting code to a variable `order_sample`
    ```{r, eval = eval_model}
    orders_sample <- orders %>%
      remote_query() %>%
      build_sql(con = con, " TABLESAMPLE BERNOULLI (0.1)") %>%
      tbl(con, .)  %>%
      inner_join(orders_view, by = "order_id") 
    ```

1. Pipe the code into the `collect()` function
    ```{r, eval = eval_model}
    orders_sample <- orders %>%
      remote_query() %>%
      build_sql(con = con, " TABLESAMPLE BERNOULLI (0.1)") %>%
      tbl(con, .) %>%
      inner_join(orders_view, by = "order_id") %>% 
      collect()
    ```

1. Load the `dbplot` library
    ```{r, eval = eval_model}
    library(dbplot)
    ```


1. Use `dbplot_histogram()` to visualize the distribution of `order_total` from `orders_sample` 
    ```{r, eval = eval_model}
    orders_sample %>% 
      dbplot_histogram(order_total, binwidth = 5)
    ```

1. Use `dbplot_histogram()` to visualize the distribution of `order_total` from `orders_view`
    ```{r, eval = eval_model}
    orders_view %>% 
      dbplot_histogram(order_total, binwidth = 5)
    ```

## Using `tidymodels` for modeling
*Fit and measure the model's performance using functions from `parsnip` and `yardstick`*

1. Load the `tidymodels` library
    ```{r, eval = eval_model}
    library(tidymodels)
    ```

1. Start with the `linear_reg()` command, pipe into `set_engine()`, and use *"lm"* as its sole argument
    ```{r, eval = eval_model}
    linear_reg() %>%
      set_engine("lm") 
    ```

1. Pipe into the `fit()` command. Use the formula: `order_total ~ order_qty`, and `orders_sample` as the `data` argument
    ```{r, eval = eval_model}
    linear_reg() %>%
      set_engine("lm") %>%
      fit(order_total ~ order_qty, data = orders_sample)
    ```

1. Assign the previous code to a variable called `parsnip_model`
    ```{r, eval = eval_model}
    parsnip_model <- linear_reg() %>%
      set_engine("lm") %>%
      fit(order_total ~ order_qty, data = orders_sample)
    ```

1. Use `bind_cols()` to add the predictions to `order_sample`.  Calculate the prediction with `predict()`
    ```{r, eval = eval_model}
    orders_sample %>% 
      bind_cols(predict(parsnip_model, orders_sample))
    ```

1. Pipe the code into the `metrics()` function.  Use `order_total` as the `truth` argument, and `.pred` as the `estimate` argument
    ```{r, eval = eval_model}
    orders_sample %>% 
      bind_cols(predict(parsnip_model, orders_sample)) %>%
      metrics(truth = order_total, estimate = .pred)
    ```

## Multi-step sampling
## Use Job panel in RStudio
## Run predictions in DB
## Fit model in R
## Score with `tidypredict`
## Save and reload models
## Integration with `tidymodels`
## Run models in DB
## Intro to `modeldb`
## `modeldb` with `tidypredict`
